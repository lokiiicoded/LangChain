{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc062d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1555d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5b8dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=api_key)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f2aac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"Python Data Handling.pdf\")\n",
    "pages = loader.load()\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f19e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "116beac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory should only store the 'answer'\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"  \n",
    ")\n",
    "\n",
    "# Build chain\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6632f4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– PDF Q&A Bot (Type 'quit' to exit)\n",
      "Gemini: The provided text is a collection of Python code snippets and explanations of dictionary and list methods.  It shows examples of creating dictionaries (like phone books and employee records), manipulating them (adding, deleting, merging), and using methods like `get()`, `update()`, `del`, and `len()`.  It also includes examples of list manipulation using `append()`, `insert()`, `remove()`, `pop()`, and `del`.  There's no overarching theme or single topic beyond demonstrating these Python functionalities.\n",
      "Gemini: This program uses dictionaries and lists to manage student information.  It demonstrates several dictionary and list methods.\n",
      "\n",
      "```python\n",
      "def manage_students():\n",
      "    \"\"\"Manages student information using dictionaries and lists.\"\"\"\n",
      "\n",
      "    students = {}  # Dictionary to store student data {student_id: [name, grades]}\n",
      "\n",
      "    while True:\n",
      "        print(\"\\nStudent Management Menu:\")\n",
      "        print(\"1. Add student\")\n",
      "        print(\"2. View student grades\")\n",
      "        print(\"3. Update student grades\")\n",
      "        print(\"4. Remove student\")\n",
      "        print(\"5. List all students\")\n",
      "        print(\"6. Exit\")\n",
      "\n",
      "        choice = input(\"Enter your choice: \")\n",
      "\n",
      "        if choice == '1':\n",
      "            student_id = input(\"Enter student ID: \")\n",
      "            name = input(\"Enter student name: \")\n",
      "            grades = []  #Start with an empty list of grades\n",
      "            students[student_id] = [name, grades]  #Add to dictionary\n",
      "            print(f\"Student {name} added.\")\n",
      "\n",
      "        elif choice == '2':\n",
      "            student_id = input(\"Enter student ID: \")\n",
      "            if student_id in students:\n",
      "                name, grades = students[student_id]\n",
      "                print(f\"Grades for {name}: {grades}\")\n",
      "            else:\n",
      "                print(\"Student not found.\")\n",
      "\n",
      "        elif choice == '3':\n",
      "            student_id = input(\"Enter student ID: \")\n",
      "            if student_id in students:\n",
      "                name, grades = students[student_id]\n",
      "                new_grade = float(input(\"Enter new grade: \"))\n",
      "                grades.append(new_grade) #Append to the grade list\n",
      "                students[student_id] = [name, grades] #Update in the dictionary\n",
      "                print(f\"Grade added for {name}.\")\n",
      "            else:\n",
      "                print(\"Student not found.\")\n",
      "\n",
      "\n",
      "        elif choice == '4':\n",
      "            student_id = input(\"Enter student ID to remove: \")\n",
      "            if student_id in students:\n",
      "                del students[student_id]\n",
      "                print(\"Student removed.\")\n",
      "            else:\n",
      "                print(\"Student not found.\")\n",
      "\n",
      "        elif choice == '5':\n",
      "            if students: #Check if the dictionary is not empty\n",
      "                print(\"List of students:\")\n",
      "                for student_id, (name, grades) in students.items():\n",
      "                    print(f\"ID: {student_id}, Name: {name}, Grades: {grades}\")\n",
      "            else:\n",
      "                print(\"No students added yet.\")\n",
      "\n",
      "        elif choice == '6':\n",
      "            print(\"Exiting program.\")\n",
      "            break\n",
      "\n",
      "        else:\n",
      "            print(\"Invalid choice. Please try again.\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    manage_students()\n",
      "```\n",
      "\n",
      "This program uses:\n",
      "\n",
      "*   **Dictionaries:** To store student data (ID as key, list of [name, grades] as value).  It uses dictionary methods like `in` (membership check),  `del` (deletion), and iteration using `.items()`.\n",
      "*   **Lists:** To store grades for each student. It uses list methods like `.append()` (adding a new grade).\n",
      "\n",
      "\n",
      "Remember to run this code in a Python environment.  The program will guide you through adding, viewing, updating, and removing student information.\n",
      "Gemini: I lack the ability to access external files, including PDFs.  Therefore, I cannot provide an answer to your question about which Python program in a PDF is the best example of using dictionaries and lists.\n",
      "ðŸ‘‹ Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ¤– PDF Q&A Bot (Type 'quit' to exit)\")\n",
    "while True:\n",
    "    query = input(\"\\nYou: \")\n",
    "    if query.lower() == \"quit\":\n",
    "        print(\"ðŸ‘‹ Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    result = qa_chain.invoke({\"question\": query})\n",
    "    print(\"Gemini:\", result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b58e1175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from streamlit) (2.3.2)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from streamlit) (2.3.1)\n",
      "Collecting pillow<12,>=7.1.0 (from streamlit)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from streamlit) (6.32.0)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Collecting jinja2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lokes\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.4/10.0 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.4/10.0 MB 21.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 19.2 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 6.0/7.0 MB 29.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 24.5 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 5.0/6.9 MB 23.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 18.9 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading narwhals-2.3.0-py3-none-any.whl (404 kB)\n",
      "Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "   ---------------------------------------- 0.0/26.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 6.3/26.1 MB 28.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 10.2/26.1 MB 24.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.2/26.1 MB 22.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.1/26.1 MB 21.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.5/26.1 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.1 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.1/26.1 MB 19.0 MB/s eta 0:00:00\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl (232 kB)\n",
      "Installing collected packages: watchdog, toml, smmap, rpds-py, pyarrow, pillow, narwhals, MarkupSafe, click, blinker, referencing, jinja2, gitdb, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\n",
      "   ----------------------------------------  0/19 [watchdog]\n",
      "   -- -------------------------------------  1/19 [toml]\n",
      "   ---- -----------------------------------  2/19 [smmap]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   -------- -------------------------------  4/19 [pyarrow]\n",
      "   ---------- -----------------------------  5/19 [pillow]\n",
      "   ---------- -----------------------------  5/19 [pillow]\n",
      "   ---------- -----------------------------  5/19 [pillow]\n",
      "   ------------ ---------------------------  6/19 [narwhals]\n",
      "   ------------ ---------------------------  6/19 [narwhals]\n",
      "   ------------ ---------------------------  6/19 [narwhals]\n",
      "   ------------ ---------------------------  6/19 [narwhals]\n",
      "   -------------- -------------------------  7/19 [MarkupSafe]\n",
      "   --------------------- ------------------ 10/19 [referencing]\n",
      "   ----------------------- ---------------- 11/19 [jinja2]\n",
      "   --------------------------- ------------ 13/19 [pydeck]\n",
      "   --------------------------- ------------ 13/19 [pydeck]\n",
      "   ------------------------------- -------- 15/19 [gitpython]\n",
      "   --------------------------------- ------ 16/19 [jsonschema]\n",
      "   --------------------------------- ------ 16/19 [jsonschema]\n",
      "   ----------------------------------- ---- 17/19 [altair]\n",
      "   ----------------------------------- ---- 17/19 [altair]\n",
      "   ----------------------------------- ---- 17/19 [altair]\n",
      "   ------------------------------------- -- 18/19 [streamlit]\n",
      "   ------------------------------------- -- 18/19 [streamlit]\n",
      "   ------------------------------------- -- 18/19 [streamlit]\n",
      "   ------------------------------------- -- 18/19 [streamlit]\n",
      "   ------------------------------------- -- 18/19 [streamlit]\n",
      "   ------------------------------------- -- 18/19 [streamlit]\n",
      "   ------------------------------------- -- 18/19 [streamlit]\n",
      "   ------------------------------------- -- 18/19 [streamlit]\n",
      "   ------------------------------------- -- 18/19 [streamlit]\n",
      "   ---------------------------------------- 19/19 [streamlit]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 altair-5.5.0 blinker-1.9.0 click-8.2.1 gitdb-4.0.12 gitpython-3.1.45 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.4.1 narwhals-2.3.0 pillow-11.3.0 pyarrow-21.0.0 pydeck-0.9.1 referencing-0.36.2 rpds-py-0.27.1 smmap-5.0.2 streamlit-1.49.1 toml-0.10.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304badc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 21:58:37.994 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-03 21:58:38.433 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\lokes\\miniconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-09-03 21:58:38.434 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-03 21:58:38.435 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-03 21:58:38.435 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-03 21:58:38.436 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-03 21:58:38.436 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-03 21:58:38.437 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-03 21:58:38.438 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-03 21:58:38.438 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "# Initialize Gemini\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=api_key)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=api_key)\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"ðŸ“„ Chat with your PDF (Gemini + LangChain)\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Python Data Handling\", type=[\"pdf\"])\n",
    "if uploaded_file is not None:\n",
    "    # Save temporarily\n",
    "    with open(\"temp.pdf\", \"wb\") as f:\n",
    "        f.write(uploaded_file.read())\n",
    "\n",
    "    # Load & split PDF\n",
    "    loader = PyPDFLoader(\"temp.pdf\")\n",
    "    pages = loader.load()\n",
    "    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = splitter.split_documents(pages)\n",
    "\n",
    "    # Create vector DB\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    # Create QA chain with memory\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory,\n",
    "        return_source_documents=False\n",
    "    )\n",
    "\n",
    "    # Chat input\n",
    "    if \"history\" not in st.session_state:\n",
    "        st.session_state.history = []\n",
    "\n",
    "    query = st.chat_input(\"Ask something about your PDF...\")\n",
    "    if query:\n",
    "        result = qa_chain.invoke({\"question\": query})\n",
    "        st.session_state.history.append((query, result[\"answer\"]))\n",
    "\n",
    "    # Display chat history\n",
    "    for q, a in st.session_state.history:\n",
    "        st.markdown(f\"**You:** {q}\")\n",
    "        st.markdown(f\"**Gemini:** {a}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c725d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
