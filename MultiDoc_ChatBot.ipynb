{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba244ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lokes\\AppData\\Local\\Temp\\ipykernel_23540\\451912724.py:51: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Document Q&A Bot (Type 'quit' to exit)\n",
      "Gemini: I'm sorry, I don't have access to the contents of any specific text files, including any that might be labeled \"RAG.\"  Therefore, I cannot explain what is in a particular RAG text file.\n",
      "Gemini: The document describes several aspects of a Retrieval Augmented Generation (RAG) system and Python dictionary methods.  The RAG system uses a retriever to find relevant documents based on embedding similarity, then a generator uses these documents to answer user queries.  The Python section details dictionary methods like `cmp()`, `del()`, `len()`, `update()`, and `get()`, showing how to compare, delete items, get length, merge, and retrieve values from dictionaries.  It also covers list methods like `append()`, `insert()`, `remove()`, `pop()`, and `del` for adding and removing items from lists.  Finally, it lists common RAG use cases, including knowledge assistants, document summarization, and customer support systems.\n",
      "Gemini: I don't know.  The provided text describes a workflow and includes data about employees in a tabular format, but it doesn't mention a CSV file or a PDF.\n",
      "Gemini: There are no files mentioned in the provided text.\n",
      "Gemini: I don't know.  The provided text describes a system for retrieving information from a vector store, not a system for handling uploaded files.\n",
      "Gemini: The provided data includes information for four employees: John Seo (ID 139), Neena Kochhar (ID 101), Luis Popp (ID 113), and John Chen (ID 110).  The data for each employee includes their ID, first name, last name, email, phone number, hire date, job ID, salary, commission percentage (all \"-\" in this dataset), manager ID, and department ID.\n",
      "Gemini: The provided text contains several Python code snippets demonstrating dictionary manipulation.  They cover:\n",
      "\n",
      "* **Creating and searching a phonebook:**  Inputting names and phone numbers, storing them in a dictionary, and searching for a phone number by name.\n",
      "* **Storing and sorting employee information:** Inputting employee numbers and names, storing them in a dictionary, and displaying the information sorted by employee number.\n",
      "* **Dictionary methods:** Examples using `.items()`, `.keys()`, `.values()`, `del`, `len()`, and `.update()` methods on dictionaries.\n",
      "* **Creating and deleting entries in a phonebook:**  Inputting names and phone numbers, storing them in a dictionary, deleting an entry by name, and displaying the remaining entries.\n",
      "* **Storing and displaying class information:** Inputting section names and class teacher names for a class, storing them in a dictionary, and displaying the information.\n",
      "\n",
      "The code examples illustrate basic dictionary operations in Python, including creation, addition, deletion, searching, sorting, and using built-in methods.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# === Load API Key ===\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "# === Initialize Gemini ===\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    google_api_key=api_key,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# === Embeddings ===\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=api_key\n",
    ")\n",
    "\n",
    "# === Load Multiple Docs ===\n",
    "docs = []\n",
    "\n",
    "# PDF\n",
    "pdf_loader = PyPDFLoader(\"Python Data Handling.pdf\")\n",
    "docs.extend(pdf_loader.load())\n",
    "\n",
    "# CSV\n",
    "csv_loader = CSVLoader(file_path=\"employees.csv\", encoding=\"utf-8\")\n",
    "docs.extend(csv_loader.load())\n",
    "\n",
    "# TXT\n",
    "txt_loader = TextLoader(\"RAG.txt\", encoding=\"utf-8\")\n",
    "docs.extend(txt_loader.load())\n",
    "\n",
    "# === Split into chunks ===\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# === Create Vector Store ===\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "# === Conversational Chain ===\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory,\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "# === Chat Loop ===\n",
    "print(\"Multi-Document Q&A Bot (Type 'quit' to exit)\")\n",
    "while True:\n",
    "    query = input(\"\\nYou: \")\n",
    "    if query.lower() == \"quit\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    result = qa_chain.invoke({\"question\": query})\n",
    "    print(\"Gemini:\", result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61005ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
